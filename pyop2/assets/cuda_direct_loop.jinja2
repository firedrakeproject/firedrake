{%- macro stagein(arg) -%}
for (int idx = 0; idx < {{ arg.data.cdim }}; ++idx) {
    {{ arg.data.name }}_shared[thread_id + idx * active_threads_count] = {{ arg.data.name}}[thread_id + idx * active_threads_count + local_offset * {{ arg.data.cdim }}];
}

for (int idx = 0; idx < {{ arg.data.cdim }}; ++idx) {
    {{ arg.data.name }}_local[idx] = {{ arg.data.name}}_shared[idx + thread_id * {{ arg.data.cdim }}];
}
{%- endmacro -%}

{%- macro stageout(arg) -%}
for (int idx = 0; idx < {{ arg.data.cdim }}; ++idx) {
    {{ arg.data.name}}_shared[idx + thread_id * {{ arg.data.cdim }}] = {{ arg.data.name }}_local[idx];
}

for (int idx = 0; idx < {{ arg.data.cdim }}; ++idx) {
    {{ arg.data.name}}[thread_id + idx * active_threads_count + local_offset * {{ arg.data.cdim }}] = {{ arg.data.name }}_shared[thread_id + idx * active_threads_count];
}
{%- endmacro -%}

{%- macro kernel_call(loop_idx) -%}
{{ parloop.kernel.name }}(
    {%- set comma = joiner(", ") -%}
    {%- for arg in parloop.args -%}
    {{- comma() -}}
    {{ arg._kernel_arg_name(loop_idx) }}
    {%- endfor -%}
    );
{%- endmacro -%}


{%- macro reduction_op(arg, lvalue, rvalue) -%}
{%- if(arg._is_INC) -%}
{{lvalue}} += {{rvalue}};
{%- elif(arg._is_MIN) -%}
if ( {{rvalue}} < {{lvalue}} ) {
    {{lvalue}} = {{rvalue}};
}
{%- elif(arg._is_MAX) -%}
if ( {{rvalue}} > {{lvalue}} ) {
    {{lvalue}} = {{rvalue}};
}
{%- endif -%}
{%- endmacro -%}

{%- macro reduction_kernel(arg) -%}
__device__ void {{ arg.data.name }}_reduction_kernel (
    volatile {{ arg.data.ctype }} *reduction_result,
    {{ arg.data.ctype }} input_value)
{
    extern __shared__ volatile {{ arg.data.ctype }} temp[];
    {{ arg.data.ctype }} dat_t;
    int tid = threadIdx.x;
    __syncthreads();
    temp[tid] = input_value;
    __syncthreads();

    // Fixup non-power of 2 blockDim
    // blockDim.x/2 rounded up to a power of 2
    int d = 1 << (31 - __clz((int)blockDim.x - 1));

    if ( tid + d < blockDim.x ) {
        dat_t = temp[tid + d];
        {{ reduction_op(arg, 'input_value', 'dat_t')|indent(8) }}
        temp[tid] = input_value;
    }

    // Reductions with more than one warp

    for ( d >>= 1; d > {{ launch.WARPSIZE }}; d >>= 1 ) {
        __syncthreads();
        if ( tid < d ) {
            dat_t = temp[tid + d];
            {{ reduction_op(arg, 'input_value', 'dat_t')|indent(12) }}
            temp[tid] = input_value;
        }
    }

    // intra-warp reduction
    __syncthreads();
    if ( tid < {{ launch.WARPSIZE }} ) {
        for ( ; d > 0; d >>= 1 ) {
            if ( tid < d ) {
                dat_t = temp[tid + d];
                {{ reduction_op(arg, 'input_value', 'dat_t')|indent(16) }}
                temp[tid] = input_value;
            }
        }
        // Update global reduction var
        if ( tid == 0 ) {
            {{ reduction_op(arg, '*reduction_result', 'input_value')|indent(12) }}
        }
    }
}
{%- endmacro -%}

{%- macro reduction_init(arg) -%}
{%- if (arg._is_INC) -%}
{{ arg.data.name }}_reduc_local[idx] = ({{arg.ctype}})0;
{%- else -%}
{{ arg.data.name }}_reduc_local[idx] = {{arg.data.name}}[idx + blockIdx.x * {{arg.data.cdim}}];
{%- endif -%}
{%- endmacro -%}

{%- macro kernel_stub() -%}
__global__ void {{ parloop._stub_name }} (int set_size
    {%- for arg in parloop.args -%}
    ,
    {{ arg.ctype }} *{{arg.data.name}}
    {%- endfor -%}
    )
{
    {%- if (parloop._needs_smem) %}
    extern __shared__ char shared[];
    {% endif %}

    {%- if (parloop._direct_non_scalar_args) -%}
    unsigned int smem_offset = {{ launch.smem_offset }};
    int local_offset;
    int active_threads_count;
    int thread_id = threadIdx.x % {{ launch.WARPSIZE }};
    // thread private storage
    {% for arg in parloop._direct_non_scalar_args -%}
    {{ arg.ctype }} {{ arg.data.name }}_local[{{ arg.data.cdim }}];
    {% endfor %}
    // smem storage
    {% for arg in parloop._direct_non_scalar_args -%}
    {{ arg.ctype }} *{{ arg.data.name }}_shared = ({{ arg.ctype }} *)(shared + smem_offset * (threadIdx.x / {{ launch.WARPSIZE }}));
    {% endfor -%}
    {%- endif %}

    {% for arg in parloop._global_reduction_args -%}
    {{ arg.data.ctype }} {{arg.data.name}}_reduc_local[{{arg.data.cdim}}];
    {% endfor %}

    {% for arg in parloop._global_reduction_args %}
    for ( int idx = 0; idx < {{ arg.data.cdim }}; ++idx ) {
        {{ reduction_init(arg) }}
    }
    {% endfor -%}

    for ( int n = threadIdx.x + blockIdx.x * blockDim.x;
          n < set_size; n+= blockDim.x * gridDim.x ) {
        {% if (parloop._direct_non_scalar_args) %}
        local_offset = n - thread_id;
        active_threads_count = min({{ launch.WARPSIZE }}, set_size - local_offset);
        {% endif %}
        {% for arg in parloop._direct_non_scalar_read_args %}
        {{ stagein(arg)|indent(8) }}
        {% endfor %}
        {{ kernel_call('n') }}
        {% for arg in parloop._direct_non_scalar_written_args %}
        {{ stageout(arg)|indent(8) }}
        {% endfor %}
    }

    {%- for arg in parloop._global_reduction_args %}
    for ( int idx = 0; idx < {{ arg.data.cdim}}; ++idx ) {
        {{ arg.data.name }}_reduction_kernel(&{{arg.data.name}}[idx + blockIdx.x * {{arg.data.cdim}}], {{arg.data.name}}_reduc_local[idx]);
    }
    {% endfor %}
}
{%- endmacro -%}

#define OP2_STRIDE(array, idx) array[idx]
{{ parloop.kernel.code }}

{% for arg in parloop._global_reduction_args -%}
{{ reduction_kernel(arg) }}
{% endfor %}

{{ kernel_stub() }}
